{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12014661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500,), learning_rate=constant; total time=  15.9s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500,), learning_rate=constant; total time=  16.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500,), learning_rate=constant; total time=  16.4s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500,), learning_rate=adaptive; total time=  16.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500,), learning_rate=adaptive; total time=  15.9s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500,), learning_rate=adaptive; total time=  17.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250), learning_rate=constant; total time=  15.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250), learning_rate=constant; total time=  16.0s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250), learning_rate=constant; total time=  16.0s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250), learning_rate=adaptive; total time=  16.2s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250), learning_rate=adaptive; total time=  20.0s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250), learning_rate=adaptive; total time=  17.8s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250, 100), learning_rate=constant; total time=  15.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250, 100), learning_rate=constant; total time=  14.2s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250, 100), learning_rate=constant; total time=  14.5s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250, 100), learning_rate=adaptive; total time=  14.9s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250, 100), learning_rate=adaptive; total time=  12.7s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(500, 250, 100), learning_rate=adaptive; total time=  13.1s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500,), learning_rate=constant; total time=  14.7s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500,), learning_rate=constant; total time=  18.1s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500,), learning_rate=constant; total time=  20.2s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500,), learning_rate=adaptive; total time=  16.8s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500,), learning_rate=adaptive; total time=  19.5s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500,), learning_rate=adaptive; total time=  19.5s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250), learning_rate=constant; total time=  19.6s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250), learning_rate=constant; total time=  18.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250), learning_rate=constant; total time=  21.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250), learning_rate=adaptive; total time=  19.1s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250), learning_rate=adaptive; total time=  18.8s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250), learning_rate=adaptive; total time=  17.6s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250, 100), learning_rate=constant; total time=  16.4s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250, 100), learning_rate=constant; total time=  15.4s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250, 100), learning_rate=constant; total time=  16.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250, 100), learning_rate=adaptive; total time=  21.1s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250, 100), learning_rate=adaptive; total time=  18.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(500, 250, 100), learning_rate=adaptive; total time=  15.3s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500,), learning_rate=constant; total time=  18.3s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500,), learning_rate=constant; total time=  17.1s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500,), learning_rate=constant; total time=  23.4s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500,), learning_rate=adaptive; total time=  32.3s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500,), learning_rate=adaptive; total time=  28.3s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500,), learning_rate=adaptive; total time=  26.1s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250), learning_rate=constant; total time=  24.1s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250), learning_rate=constant; total time=  30.6s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250), learning_rate=constant; total time=  28.1s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250), learning_rate=adaptive; total time=  20.5s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250), learning_rate=adaptive; total time=  17.7s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250), learning_rate=adaptive; total time=  22.7s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250, 100), learning_rate=constant; total time=  17.4s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250, 100), learning_rate=constant; total time=  17.1s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250, 100), learning_rate=constant; total time=  17.6s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250, 100), learning_rate=adaptive; total time=  14.7s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250, 100), learning_rate=adaptive; total time=   7.7s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(500, 250, 100), learning_rate=adaptive; total time=  14.5s\n",
      "[+] Number of training samples: 936\n",
      "[+] Number of testing samples: 312\n",
      "[+] Number of features: 180\n",
      "Best parameters: {'alpha': 0.01, 'hidden_layer_sizes': (500, 250), 'learning_rate': 'constant'}\n",
      "Accuracy: 69.55%\n"
     ]
    }
   ],
   "source": [
    "import soundfile\n",
    "import numpy as np\n",
    "import PySimpleGUI as sg\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import pyaudio\n",
    "import wave\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "AVAILABLE_EMOTIONS = {\n",
    "    \"neutral\",\n",
    "    \"calm\",\n",
    "    \"happy\",\n",
    "    \"sad\",\n",
    "    \"angry\",\n",
    "    \"fearful\",\n",
    "    \"disguest\",\n",
    "    \"surprised\"\n",
    "}\n",
    "\n",
    "def extract_feature(file_name, **kwargs):\n",
    "\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X, sample_rate = librosa.load(file_name)\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_data(test_size=0.2):\n",
    "    X, y = [], []\n",
    "    for file in glob.glob(\"C:\\\\Users\\\\Raaj\\\\Machine Learning\\\\Speech Emotion Recognition\\\\ravdess-emotional-speech-audio\\\\Actor_*\\\\\\\\*.wav\"):\n",
    "        basename = os.path.basename(file)\n",
    "        emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "        if emotion not in AVAILABLE_EMOTIONS:\n",
    "            continue\n",
    "        features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        X.append(features)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(test_size=0.25)\n",
    "\n",
    "# Preprocessing: Normalize input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model tuning: Grid search with cross-validation\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(500,), (500, 250), (500, 250, 100)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(MLPClassifier(max_iter=1500), param_grid, cv=3, verbose=2)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
    "print(\"[+] Number of features:\", X_train.shape[1])\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "\n",
    "if not os.path.isdir(\"result\"):\n",
    "    os.mkdir(\"result\")\n",
    "\n",
    "pickle.dump(model, open(\"result/mlp_classifier.model\", \"wb\"))\n",
    "\n",
    "THRESHOLD = 500\n",
    "CHUNK_SIZE = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 16000\n",
    "SILENCE = 30\n",
    "\n",
    "def is_silent(snd_data):\n",
    "    return max(snd_data) < THRESHOLD\n",
    "\n",
    "def normalize(snd_data):\n",
    "    MAXIMUM = 16384\n",
    "    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\n",
    "\n",
    "    r = array('h')\n",
    "    for i in snd_data:\n",
    "        r.append(int(i*times))\n",
    "    return r\n",
    "\n",
    "def trim(snd_data):\n",
    "    def _trim(snd_data):\n",
    "        snd_started = False\n",
    "        r = array('h')\n",
    "\n",
    "        for i in snd_data:\n",
    "            if not snd_started and abs(i)>THRESHOLD:\n",
    "                snd_started = True\n",
    "                r.append(i)\n",
    "\n",
    "            elif snd_started:\n",
    "                r.append(i)\n",
    "        return r\n",
    "\n",
    "    snd_data = _trim(snd_data)\n",
    "    snd_data.reverse()\n",
    "    snd_data = _trim(snd_data)\n",
    "    snd_data.reverse()\n",
    "    return snd_data\n",
    "\n",
    "def add_silence(snd_data, seconds):\n",
    "    r = array('h', [0 for i in range(int(seconds*RATE))])\n",
    "    r.extend(snd_data)\n",
    "    r.extend([0 for i in range(int(seconds*RATE))])\n",
    "    return r\n",
    "def record():\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=1, rate=RATE,\n",
    "        input=True, output=True,\n",
    "        frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "    num_silent = 0\n",
    "    snd_started = False\n",
    "\n",
    "    r = array('h')\n",
    "\n",
    "    while 1:\n",
    "        snd_data = array('h', stream.read(CHUNK_SIZE))\n",
    "        if byteorder == 'big':\n",
    "            snd_data.byteswap()\n",
    "        r.extend(snd_data)\n",
    "\n",
    "        silent = is_silent(snd_data)\n",
    "\n",
    "        if silent and snd_started:\n",
    "            num_silent += 1\n",
    "        elif not silent and not snd_started:\n",
    "            snd_started = True\n",
    "\n",
    "        if snd_started and num_silent > SILENCE:\n",
    "            break\n",
    "\n",
    "    sample_width = p.get_sample_size(FORMAT)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    r = normalize(r)\n",
    "    r = trim(r)\n",
    "    r = add_silence(r, 0.5)\n",
    "    return sample_width, r\n",
    "\n",
    "def record_to_file(path):\n",
    "    sample_width, data = record()\n",
    "    data = pack('<' + ('h'*len(data)), *data)\n",
    "\n",
    "    wf = wave.open(path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(sample_width)\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(data)\n",
    "    wf.close()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80659aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please talk\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = pickle.load(open(\"result/mlp_classifier.model\", \"rb\"))\n",
    "    print(\"Please talk\")\n",
    "    filename = \"test.wav\"\n",
    "    record_to_file(filename)\n",
    "    features = extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1)\n",
    "    result = model.predict(features)[0]\n",
    "    outpu=\"The emotion speaker expressing is : \"+result\n",
    "    \n",
    "layout = [[sg.Text(outpu)], [sg.Button(\"OK\")]]\n",
    "window = sg.Window(\"Results\", layout, margins=(100, 50))\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    if event == \"OK\" or event == sg.WIN_CLOSED:\n",
    "        break\n",
    "\n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed866917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dcf9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed52331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c8378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59fb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b3f779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f557d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b549676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1fd9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8b3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f8e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c875c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
